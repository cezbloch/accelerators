{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8359a97b",
   "metadata": {},
   "source": [
    "# Matrix Multiplication with PyCUDA\n",
    "\n",
    "This notebook demonstrates how to perform matrix multiplication using PyCUDA. The CUDA kernel implementation is left empty for you to complete as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "from cuda_helpers import profile_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba9101e",
   "metadata": {},
   "source": [
    "## Define Matrices\n",
    "\n",
    "Let's define two matrices to multiply. You can change their size and values as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22163b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two matrices A and B\n",
    "N = 1024\n",
    "A = np.random.randn(N, N).astype(np.float32)\n",
    "B = np.random.randn(N, N).astype(np.float32)\n",
    "print(\"Matrix A:\\n\", A)\n",
    "print(\"Matrix B:\\n\", B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f15d57f",
   "metadata": {},
   "source": [
    "## Perform Matrix Multiplication on the GPU\n",
    "\n",
    "We will multiply matrices A and B using a CUDA kernel. The kernel code is left empty for you to complete as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate GPU memory and transfer matrices\n",
    "d_a = cuda.mem_alloc(A.nbytes)\n",
    "d_b = cuda.mem_alloc(B.nbytes)\n",
    "d_c = cuda.mem_alloc(A.nbytes)\n",
    "cuda.memcpy_htod(d_a, A)\n",
    "cuda.memcpy_htod(d_b, B)\n",
    "\n",
    "# CUDA kernel for matrix multiplication (to be completed)\n",
    "kernel_code = \"\"\"\n",
    "__global__ void matmul(float *A, float *B, float *C, int N) {\n",
    "    // TODO: Implement matrix multiplication kernel\n",
    "    // blockIdx, blockDim, threadIdx, gridDim\n",
    "    float sum = 0;\n",
    "    int2 global_id = make_int2(blockIdx.x * blockDim.x + threadIdx.x,\n",
    "                               blockIdx.y * blockDim.y + threadIdx.y);\n",
    "\n",
    "    if (global_id.x >= N || global_id.y >= N) {\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    for (int i = 0; i < N; i++) {\n",
    "        int aij = global_id.y * N + i;\n",
    "        int bij = i * N + global_id.x;\n",
    "        sum  += A[aij] * B[bij];\n",
    "    }\n",
    "\n",
    "    int cij = global_id.y * N + global_id.x;\n",
    "    C[cij] = sum;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "mod = SourceModule(kernel_code)\n",
    "matmul = mod.get_function(\"matmul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2cbb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = (8, 8, 1)\n",
    "grid_size = (A.shape[0] // block_size[0], A.shape[1] // block_size[1], 1)\n",
    "\n",
    "print(f'Launching with grid_size={grid_size}, block_size={block_size}')\n",
    "\n",
    "n_warmup = 2\n",
    "n_iters = 20\n",
    "\n",
    "launch = lambda: matmul(d_a, d_b, d_c, np.int32(N), block=block_size, grid=grid_size)\n",
    "_ = profile_gpu(launch, n_warmup=n_warmup, n_iters=n_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6236bc",
   "metadata": {},
   "source": [
    "## Display Results\n",
    "\n",
    "After running the kernel, copy the result back to the host and display it.\n",
    "\n",
    "Refer to the [solution](./CUDA/matrix_multiplication_solution_global.cu) if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy result from GPU and display\n",
    "C = np.empty_like(A)\n",
    "cuda.memcpy_dtoh(C, d_c)\n",
    "c_numpy = np.matmul(A, B)\n",
    "print(\"Result matrix C (A x B):\\n\", C)\n",
    "\n",
    "np.testing.assert_almost_equal(C, c_numpy, decimal=3)\n",
    "# Note: You need to implement the kernel for correct results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
