{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Test\n",
    "\n",
    "This notebook is intended to run before the course to verify if the machines and environment works correctly.\n",
    "It can, and should be run by multiple people at the same time so that we make sure multiple people can work together.\n",
    "\n",
    "All cells should get executed and you should scroll down and see if the last message was printed. If not, report the problem to the lecturer or organizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeeHive specific setup\n",
    "\n",
    "If you are working on a BeeHive cluster and share a GPU with other people the lines below are neede to make the notebooks work. If values \"0\" are assigned then first GPU will be used. If values \"1\" are assigned then second GPU and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GPU_DEVICE_ORDINAL\"] = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the test\n",
    "\n",
    "We won't go into details about the cell's meaning now - it will be explained during the course in the next notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "import numpy as np\n",
    "\n",
    "%load_ext pyopencl.ipython_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "platform = cl.get_platforms()[0]\n",
    "\n",
    "ctx = cl.Context(\n",
    "    dev_type=cl.device_type.ALL, \n",
    "    properties=[(cl.context_properties.PLATFORM, platform)])    \n",
    "\n",
    "queue = cl.CommandQueue(ctx, properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "    \n",
    "devices = ctx.get_info(cl.context_info.DEVICES)\n",
    "for d in devices:\n",
    "    print(f\"device={d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_gpu(function, n, queue, global_size, local_size, *args):\n",
    "    times = np.zeros(n)\n",
    "    function(queue, global_size, local_size, *args).wait()\n",
    "    function(queue, global_size, local_size, *args).wait()\n",
    "    \n",
    "    for i in range(n):\n",
    "        e = function(queue, global_size, local_size, *args)\n",
    "        e.wait()\n",
    "        elapsed = (e.profile.end - e.profile.start) * 1e-6\n",
    "        times[i] = elapsed\n",
    "\n",
    "    avg_ms = np.mean(times)\n",
    "    median_ms = np.median(times)\n",
    "    variance = np.var(times)\n",
    "    std = np.std(times)\n",
    "    print(f\"{function.function_name} took on average {avg_ms:.4f} ms, with median {median_ms:.4f} ms, variance {variance:.4f} ms, standard deviation {std:.4f} ms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = np.int32(2**25)\n",
    "h_a = np.full(N, 1).astype(np.int32)\n",
    "h_b = np.full(N, 2).astype(np.int32)\n",
    "\n",
    "print(f\"Working with {len(h_a):,} elements with {h_a.nbytes:,} bytes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create required GPU buffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = cl.mem_flags\n",
    "\n",
    "d_a = cl.Buffer(ctx, flags.READ_ONLY | flags.COPY_HOST_PTR, hostbuf=h_a)\n",
    "d_b = cl.Buffer(ctx, flags.READ_ONLY | flags.COPY_HOST_PTR, hostbuf=h_b)\n",
    "d_c = cl.Buffer(ctx, flags.WRITE_ONLY, h_a.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the kernel below to add elements from two arrays and write the result back to a third array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cl_kernel -o \"-cl-fast-relaxed-math\"\n",
    "\n",
    "__kernel void add_vectors(__global const int *a, __global const int *b, __global int *c)\n",
    "{\n",
    "    int gid = get_global_id(0);\n",
    "    c[gid] = 2 * a[gid] + b[gid];\n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create appropriate execution configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_work_size = (64,)\n",
    "global_work_size = (N,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute and profile the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_gpu(add_vectors, 20, \n",
    "            queue, \n",
    "            global_work_size, \n",
    "            local_work_size,\n",
    "            d_a,\n",
    "            d_b, \n",
    "            d_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h_c = np.zeros(N).astype(np.int32)\n",
    "cl.enqueue_copy(queue, h_c, d_c)\n",
    "\n",
    "def compute_linear_equations_cpu(a, b):\n",
    "    return 2 * a + b\n",
    "\n",
    "numpy_res = compute_linear_equations_cpu(h_a, h_b)\n",
    "np.testing.assert_array_equal(numpy_res, h_c)\n",
    "\n",
    "print(\"If this message got printed in the output cell then everything worked correctly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
