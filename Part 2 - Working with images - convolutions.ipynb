{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Working with images\n",
    "\n",
    "The goal of this notebook is to get you familiar with OpenCL API related to images. Until now, we've worked with buffers and images are handled a bit differently. \n",
    "\n",
    "The exercises will is to implement a filter that can be applied to an image. We're going to define a relatively small, fixed size 3x3 matrix - also sometimes called a kernel, but we'll stick to the name filter. This matrix will be applied to every pixel in the image. You can think about it as a transform, which processes our image. Some common examples include:\n",
    "* image blurring with [Box blur](https://en.wikipedia.org/wiki/Box_blur)\n",
    "* edge detection with [Sobel Filter](https://en.wikipedia.org/wiki/Sobel_operator)\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "Define a few neccessary setup steps. They are described in details in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GPU_DEVICE_ORDINAL\"] = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries and extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "import numpy as np\n",
    "\n",
    "%load_ext pyopencl.ipython_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create context and queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = cl.get_platforms()[0]\n",
    "\n",
    "ctx = cl.Context(\n",
    "    dev_type=cl.device_type.ALL, \n",
    "    properties=[(cl.context_properties.PLATFORM, platform)])    \n",
    "\n",
    "queue = cl.CommandQueue(ctx, properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "    \n",
    "devices = ctx.get_info(cl.context_info.DEVICES)\n",
    "for d in devices:\n",
    "    print(f\"device={d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image copy exercise\n",
    "\n",
    "Let's start with the host code that reads an image from a file into a numpy array. Numpy is a very popular Python library for working with arrays and matrices. Many operations are simple and convenient using numpy.\n",
    "\n",
    "For reading the image into numpy array we will use another popular Computer Vision library - OpenCV. We are going to prefix variable names with:\n",
    "* h_ or host_ - to indicate that variable refers to an object in host (CPU) memory\n",
    "* d_ or device_ - to indicate that variable refers to device (GPU) memory\n",
    "\n",
    "NOTE: The image is assumed to be accessed from the \"Bee Hive\" cluster. Change the path if you are working in a different environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image_path = \"/mnt/projects_pl/team_neon/TestData/Images/SDR_8bit/Desktop/4K/Desktop.bmp\"\n",
    "\n",
    "h_image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "h_image = cv2.cvtColor(h_image, cv2.COLOR_BGR2BGRA) #add Alpha channel - needed for GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll define a helper function for profiling GPU kernels. In this case by profiling we mean measuring execution time. Since the code executes asynchronously on GPU we cannot just use methods known from Python like using \"time\" module. \n",
    "\n",
    "In PyOpenCL we can easily retrieve two timestamps collected from GPU clock and we can compute the time GPU has spent on executing the kernel.\n",
    "\n",
    "Additionally, we'll execute the kernel \"n\" number of times and take the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_gpu(function, n, queue, global_size, local_size, *args):\n",
    "    times = np.zeros(n)\n",
    "    function(queue, global_size, local_size, *args).wait()\n",
    "    function(queue, global_size, local_size, *args).wait()\n",
    "    \n",
    "    for i in range(n):\n",
    "        e = function(queue, global_size, local_size, *args)\n",
    "        e.wait()\n",
    "        elapsed = (e.profile.end - e.profile.start) * 1e-6\n",
    "        times[i] = elapsed\n",
    "\n",
    "    avg_ms = np.mean(times)\n",
    "    median_ms = np.median(times)\n",
    "    variance = np.var(times)\n",
    "    std = np.std(times)\n",
    "\n",
    "    print(f\"{function.function_name} took on average {avg_ms:.4f} ms, with median {median_ms:.4f} ms, variance {variance:.4f} ms, standard deviation {std:.4f} ms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we'll define a function to display an image in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "def show_image(bgra_image):\n",
    "    _, ret = cv2.imencode('.png', bgra_image)\n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how the image looks like. This is an example of a desktop screenshot, so a very commmon content that we encode in DisplayLink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(h_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the image loaded was stored in CPU memory. In order to process it in GPU we need to transfer it to GPU. Additionally we'll extract the image dimensions from the shape property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = h_image.shape[0]\n",
    "width = h_image.shape[1]\n",
    "nr_channels = h_image.shape[2]\n",
    "\n",
    "d_image = cl.image_from_array(ctx, h_image, nr_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For copying the image we also need to create a second image to which the first one will be copied to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = cl.ImageFormat(cl.channel_order.RGBA, cl.channel_type.UNSIGNED_INT8)\n",
    "\n",
    "d_output = cl.Image(ctx, cl.mem_flags.WRITE_ONLY, fmt, shape=(width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a copy kernel\n",
    "\n",
    "Your first task is to write an OpenCL kernel which will copy pixels from one image to another. Modify the code below to read the pixels, and write them back into output image.\n",
    "\n",
    "* To read pixel from a texture you can use the [read_image](https://man.opencl.org/read_imagei2d.html) function.\n",
    "* To write pixel use [write_image](https://man.opencl.org/write_image2d.html)\n",
    "* To retrieve a thread ID you can use the [get_global_id](https://man.opencl.org/get_global_id.html) function.\n",
    "* Anything else can be found on the [OpenCL 1.2 reference card](https://www.khronos.org/files/opencl-1-2-quick-reference-card.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cl_kernel\n",
    "\n",
    "__kernel void copy_image(read_only image2d_t image, write_only image2d_t output)\n",
    "{    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify this section to adjust execution configuration - the number and size of work groups. This can be solved in many ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_work_size = (8,8)\n",
    "global_work_size = (width,height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below schedules the kernel execution and reads the data back to the CPU. This code section is setup correctly so you should not modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep this cell unchanged\n",
    "\n",
    "# recreate empty output buffer\n",
    "d_output = cl.Image(ctx, cl.mem_flags.WRITE_ONLY, fmt, shape=(width, height))\n",
    "\n",
    "# schedule 'copy_image' kernel execution onto a GPU\n",
    "profile_gpu(copy_image, 20, queue,\n",
    "            global_work_size, \n",
    "            local_work_size,\n",
    "            d_image,\n",
    "            d_output)\n",
    "\n",
    "# initialize CPU output buffer\n",
    "h_output = np.zeros_like(h_image)\n",
    "\n",
    "# schedule copy from GPU resource to CPU memory\n",
    "_ = cl.enqueue_copy(queue=queue,\n",
    "                dest=h_output,\n",
    "                src=d_output,\n",
    "                origin=(0, 0),\n",
    "                region=(width, height)\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debugging purposes you can modify those lines that print pixel values in the cell below. \n",
    "\n",
    "Also the copied image is displayed in the cell area so you can visually assess if it was copied correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(h_image[:2, :2, :])\n",
    "display(h_output[:2, :2, :])\n",
    "print(f\"Input and output are the same: {np.array_equal(h_image, h_output)}\")\n",
    "\n",
    "# display image in the cell below\n",
    "show_image(h_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the [solution](./open_day/copy_image_solution.txt) if you get stuck.\n",
    "\n",
    "## Implement Box Blur\n",
    "\n",
    "Now that you have written a copy kernel we have a good basis to implement a convolutional filter. \n",
    "* by filter we mean a mathematical operation on the pixels. \n",
    "* by convolutional we mean that conceptually a window will slide through an image and apply the operation.\n",
    "\n",
    "What that means in practice is, that additionally to reading a pixel value you will have to read the pixels surrounding it. You can refer to the [Implementation](https://en.wikipedia.org/wiki/Box_blur#Implementation) section of Wikipedia site on Box Blur. You will need to extend the copy kernel written previously with:\n",
    "* read 9 pixels in total. One in the middle and 8 surrounding it.\n",
    "* Take a mean of 9 pixels. Pay attention to data types.\n",
    "* write the mean pixel to the output image.\n",
    "* we'll add sampler to read_imagei function so that we don't have to think about handling edges of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cl_kernel\n",
    "\n",
    "__constant sampler_t sampler = CLK_NORMALIZED_COORDS_FALSE | CLK_ADDRESS_CLAMP | CLK_FILTER_NEAREST;\n",
    "\n",
    "__kernel void box_blur(read_only image2d_t image, write_only image2d_t output)\n",
    "{\n",
    "           \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the copy image example, the code below schedules kernel execution. Feel free to experiment with local and global work sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_work_size = (8,8)\n",
    "global_work_size = (width,height)\n",
    "\n",
    "# keep below code cell unchanged\n",
    "\n",
    "# recreate empty output buffer\n",
    "d_blur_output = cl.Image(ctx, cl.mem_flags.WRITE_ONLY, fmt, shape=(width, height))\n",
    "\n",
    "# schedule 'box_blur' kernel execution onto a GPU\n",
    "profile_gpu(box_blur, 20, queue,\n",
    "            global_work_size, \n",
    "            local_work_size,\n",
    "            d_image,\n",
    "            d_blur_output)\n",
    "\n",
    "# initialize CPU output buffer\n",
    "h_blur_output = np.zeros_like(h_image)\n",
    "\n",
    "# schedule copy from GPU resource to CPU memory\n",
    "_ = cl.enqueue_copy(queue=queue,\n",
    "                dest=h_blur_output,\n",
    "                src=d_blur_output,\n",
    "                origin=(0, 0),\n",
    "                region=(width, height)\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help with debugging we display 128x128 pixels of upper left part of the original image and a blurred image. Does the second one look blurred?\n",
    "\n",
    "Click [blurred_image.bmp](./blurred_image.bmp) to view the full image in a separate tab to check how it looks.\n",
    "\n",
    "Refer to the [solution](./open_day/box_blur_solution.txt) if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image in the cell below\n",
    "show_image(h_image[:128, :128, :])\n",
    "show_image(h_blur_output[:128, :128, :])\n",
    "_ = cv2.imwrite(\"blurred_image.bmp\", h_blur_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implement edge detection - Sobel filter\n",
    "\n",
    "To implement any filter we will extend the Box Blur code to load 3x3 filter matrix into GPU and perform calculations on it. To achieve that you need to perform these extra steps:\n",
    "* pass additional parameter storing the filter weights - load the buffer storing filter weights into GPU memory - look [here](https://en.wikipedia.org/wiki/Sobel_operator#Formulation) for the values. They will be:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} -1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "* extend simple mean calculation to be weighted mean - in practice you just have to multiply all 9 pixels by corresponding weights.\n",
    "* Sobel filter works on [luminance](https://en.wikipedia.org/wiki/Luma_(video)) - pixel intensity. To calculate it you can use simple version of the formula:\n",
    "\n",
    "$$\n",
    "\\frac{Red + 2 Green + Blue}{4}\n",
    "$$\n",
    "\n",
    "* write the luminance as all channels i.e. R G & B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cl_kernel\n",
    "\n",
    "__constant sampler_t sampler = CLK_NORMALIZED_COORDS_FALSE | CLK_ADDRESS_CLAMP | CLK_FILTER_NEAREST;\n",
    "\n",
    "__kernel void sobel_filter(read_only image2d_t image, const __global float* my_filter, write_only image2d_t output)\n",
    "{\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below schedules execution to the GPU. Notice that we have added an extra buffer that stores values of 3x3 filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_work_size = (8,8)\n",
    "global_work_size = (width, height)\n",
    "h_filter = np.array(\n",
    "    [[-1, 0, 1], \n",
    "     [-2, 0, 2], \n",
    "     [-1, 0, 1]], \n",
    "    dtype=np.float32)\n",
    "\n",
    "# keep below code cell unchanged\n",
    "\n",
    "# recreate empty output buffer\n",
    "d_filter_output = cl.Image(ctx, cl.mem_flags.WRITE_ONLY, fmt, shape=(width, height))\n",
    "d_filter = cl.Buffer(ctx, flags=cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_filter)\n",
    "\n",
    "# schedule 'sobel_filter' kernel execution onto a GPU\n",
    "profile_gpu(sobel_filter, 20, queue,\n",
    "            global_work_size, \n",
    "            local_work_size,\n",
    "            d_image,\n",
    "            d_filter,\n",
    "            d_filter_output)\n",
    "\n",
    "# initialize CPU output buffer\n",
    "h_filter_output = np.zeros_like(h_image)\n",
    "\n",
    "# schedule copy from GPU resource to CPU memory\n",
    "_ = cl.enqueue_copy(queue=queue,\n",
    "                dest=h_filter_output,\n",
    "                src=d_filter_output,\n",
    "                origin=(0, 0),\n",
    "                region=(width, height)\n",
    "               )\n",
    "\n",
    "show_image(h_filter_output)\n",
    "_ = cv2.imwrite(\"sobel_filter.bmp\", h_filter_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click [sobel_filter.bmp](./sobel_filter.bmp) to view the full image in a separate tab to check how it looks.\n",
    "\n",
    "Refer to the [solution](./open_day/sobel_filter_solution.txt) if you get stuck.\n",
    "\n",
    "If interested, you can try out other types of filters. [Here](https://en.wikipedia.org/wiki/Kernel_(image_processing)) is a wikipedia list of popular 3x3 filters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
